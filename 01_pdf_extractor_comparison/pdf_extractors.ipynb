{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating PDF extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: The code throughout this notebook is quite bad and largely undocumented, as it was only used for quick-and-dirty experiments.\n",
    "\n",
    "TLDR: PyMuPDF best among the tested PDF extraction libraries. Detection of footnotes and their resolution works decent.\n",
    "\n",
    "For a more extensive interpretation of the results, please see the thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U PyMuPDF\n",
    "import fitz\n",
    "\n",
    "!pip3 install -U pdfminer.six\n",
    "from pdfminer.high_level import extract_text as pdfminer_extract_text\n",
    "from pdfminer.high_level import extract_pages as pdfminer_extract_pages\n",
    "from pdfminer.layout import LTTextContainer as pdfminer_LTTextContainer\n",
    "\n",
    "!pip3 install -U PyPDF2\n",
    "import PyPDF2\n",
    "\n",
    "!pip3 install -U pdfplumber\n",
    "import pdfplumber\n",
    "\n",
    "!pip3 install -U borb\n",
    "from borb.pdf import PDF as BorbPDF\n",
    "from borb.toolkit.text.simple_text_extraction import (\n",
    "    SimpleTextExtraction as BorbTextExtraction,\n",
    ")\n",
    "\n",
    "!pip3 install -U tika\n",
    "from tika import parser as tika_parser\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>n_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2665651</td>\n",
       "      <td>ngo</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2665650</td>\n",
       "      <td>ngo</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2665649</td>\n",
       "      <td>ngo</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id user_type                                           filename  \\\n",
       "0  2665651       ngo  ../24212003_requirements_for_artificial_intell...   \n",
       "1  2665650       ngo  ../24212003_requirements_for_artificial_intell...   \n",
       "2  2665649       ngo  ../24212003_requirements_for_artificial_intell...   \n",
       "\n",
       "   n_pages  \n",
       "0        7  \n",
       "1        2  \n",
       "2       39  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedbacks = pd.read_csv(\n",
    "    \"../24212003_requirements_for_artificial_intelligence/patched_feedbacks.csv\"\n",
    ")\n",
    "attachments = pd.read_csv(\n",
    "    \"../24212003_requirements_for_artificial_intelligence/attachments.csv\"\n",
    ")\n",
    "\n",
    "attachments = pd.merge(feedbacks, attachments)[[\"id\", \"user_type\", \"filename\"]]\n",
    "attachments[\"filename\"] = (\n",
    "    \"../24212003_requirements_for_artificial_intelligence/\" + attachments[\"filename\"]\n",
    ")\n",
    "attachments[\"n_pages\"] = attachments[\"filename\"].map(lambda f: fitz.open(f).page_count)\n",
    "\n",
    "attachments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rng(analysis: int):\n",
    "    \"\"\"Return a NumPy random number generator - make code cells deterministic\n",
    "    independent of how often or in which order they are executed.\n",
    "    \"\"\"\n",
    "    return np.random.default_rng(seed=123 * analysis)\n",
    "\n",
    "\n",
    "def stratified_sample(df: pd.DataFrame, by: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Perform a stratified sample: sample n elements for each 'by' stratum.\"\"\"\n",
    "    grouped = df.groupby(by, group_keys=False)\n",
    "    return grouped.apply(lambda x: x.sample(min(len(x), n), random_state=12345))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read errors & time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A common way of executing extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(extractor, extractor_name, attachments, timeout=5 * 60):\n",
    "    successes, failures = 0, 0\n",
    "    start = time.time()\n",
    "\n",
    "    for pdf in attachments[\"filename\"]:\n",
    "        if time.time() - start > timeout:\n",
    "            break\n",
    "        try:\n",
    "            text = extractor(pdf)\n",
    "\n",
    "            # Should have extracted at least some text\n",
    "            assert type(text) in (str, list)\n",
    "            if type(text) == str:\n",
    "                assert len(text) > 100\n",
    "            elif type(text) == list:\n",
    "                assert sum(len(x) for x in text) > 100\n",
    "\n",
    "            successes += 1\n",
    "        except:\n",
    "            print(f\"Failure to read {pdf}\")\n",
    "            failures += 1\n",
    "\n",
    "    runtime = time.time() - start\n",
    "    runtime = runtime if runtime < timeout else timeout\n",
    "\n",
    "    return {\n",
    "        \"name\": extractor_name,\n",
    "        \"successes\": successes,\n",
    "        \"failures\": failures,\n",
    "        \"runtime\": runtime,\n",
    "    }\n",
    "\n",
    "\n",
    "results_1 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining extractor methods for each library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure to read ../24212003_requirements_for_artificial_intelligence/attachments/2665436.pdf\n"
     ]
    }
   ],
   "source": [
    "def fitz_extractor(pdf):\n",
    "    doc = fitz.open(pdf)\n",
    "    return [page.get_text() for page in doc]\n",
    "\n",
    "\n",
    "results_1.append(run_experiment(fitz_extractor, \"fitz\", attachments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure to read ../24212003_requirements_for_artificial_intelligence/attachments/2665436.pdf\n"
     ]
    }
   ],
   "source": [
    "def pdfminer_extractor(pdf):\n",
    "    return pdfminer_extract_text(pdf)\n",
    "\n",
    "\n",
    "results_1.append(run_experiment(pdfminer_extractor, \"pdfminer\", attachments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure to read ../24212003_requirements_for_artificial_intelligence/attachments/2665436.pdf\n"
     ]
    }
   ],
   "source": [
    "def pypdf2_extractor(pdf):\n",
    "    reader = PyPDF2.PdfReader(pdf)\n",
    "    return [page.extract_text() for page in reader.pages]\n",
    "\n",
    "\n",
    "results_1.append(run_experiment(pypdf2_extractor, \"PyPDF2\", attachments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure to read ../24212003_requirements_for_artificial_intelligence/attachments/2665436.pdf\n"
     ]
    }
   ],
   "source": [
    "def pdfplumber_extractor(pdf):\n",
    "    with pdfplumber.open(pdf) as doc:\n",
    "        return [page.extract_text() for page in doc.pages]\n",
    "\n",
    "\n",
    "results_1.append(run_experiment(pdfplumber_extractor, \"pdfplumber\", attachments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n",
      "Unable to process XMP meta-data\n"
     ]
    }
   ],
   "source": [
    "def borb_extractor(pdf):\n",
    "    ste = BorbTextExtraction()\n",
    "    with open(pdf, \"rb\") as in_file_handle:\n",
    "        doc = BorbPDF.loads(in_file_handle, [ste])\n",
    "        return list(ste.__dict__[\"_text_per_page\"].values())\n",
    "\n",
    "\n",
    "results_1.append(run_experiment(borb_extractor, \"borb\", attachments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 14:25:00,628 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar to /tmp/tika-server.jar.\n",
      "2022-10-25 14:25:04,182 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar.md5 to /tmp/tika-server.jar.md5.\n",
      "2022-10-25 14:25:04,821 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    }
   ],
   "source": [
    "def tika_extractor(pdf):\n",
    "    return tika_parser.from_file(pdf)[\"content\"]\n",
    "\n",
    "\n",
    "results_1.append(run_experiment(tika_extractor, \"tika\", attachments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collecting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_df = pd.DataFrame(results_1).sort_values(\n",
    "    [\"runtime\", \"successes\"], ascending=[True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTÜV-Association Position Paper on batteries and waste batteries\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nhttp://www.tuev-verband.de/\\n\\n\\n \\n\\n \\n\\nhttp://www.tuev-verband.de/\\n\\n\\n \\n\\nhttp://www.tuev-verband.de/\\n\\n\\n \\n\\nhttp://www.tuev-verband.de/\\n\\n\\n \\n\\nhttp://www.tuev-verband.de/\\n\\n\\nhttp://www.tuev-verband.de/\\n\\n\\nhttp://www.tuev-verband.de/\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"../24212003_requirements_for_artificial_intelligence/attachments/2665436.pdf\"\n",
    "tika_extractor(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As tika also fails to properly read 2665436's attachment, update df\n",
    "results_1_df.loc[results_1_df[\"name\"] == \"tika\", \"successes\"] -= 1\n",
    "results_1_df.loc[results_1_df[\"name\"] == \"tika\", \"failures\"] += 1\n",
    "\n",
    "results_1_df.to_csv(\"results/results_1_runtime_errors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>successes</th>\n",
       "      <th>failures</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fitz</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>7.079093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tika</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>35.953465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PyPDF2</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>93.199966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pdfminer</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>230.098631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pdfplumber</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>292.154443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>borb</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  successes  failures     runtime\n",
       "0        fitz        255         1    7.079093\n",
       "1        tika        255         1   35.953465\n",
       "2      PyPDF2        255         1   93.199966\n",
       "3    pdfminer        255         1  230.098631\n",
       "4  pdfplumber        255         1  292.154443\n",
       "5        borb         22         0  300.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"results/results_1_runtime_errors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>n_pages</th>\n",
       "      <th>page</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2665648</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2665648</td>\n",
       "      <td>attachments/2665648.pdf#page=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2663366</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2663366</td>\n",
       "      <td>attachments/2663366.pdf#page=9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2665480</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>2665480</td>\n",
       "      <td>attachments/2665480.pdf#page=38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                      user_type  \\\n",
       "3    2665648  academic_research_institution   \n",
       "196  2663366  academic_research_institution   \n",
       "106  2665480  academic_research_institution   \n",
       "\n",
       "                                              filename  n_pages  page  \\\n",
       "3    ../24212003_requirements_for_artificial_intell...        8     1   \n",
       "196  ../24212003_requirements_for_artificial_intell...       13     9   \n",
       "106  ../24212003_requirements_for_artificial_intell...       64    38   \n",
       "\n",
       "     source_id                           source  \n",
       "3      2665648   attachments/2665648.pdf#page=1  \n",
       "196    2663366   attachments/2663366.pdf#page=9  \n",
       "106    2665480  attachments/2665480.pdf#page=38  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_2 = stratified_sample(attachments, \"user_type\", 5)\n",
    "rng_2 = rng(1)\n",
    "sample_2[\"page\"] = sample_2[\"n_pages\"].map(lambda n: rng_2.choice(n) + 1)\n",
    "sample_2[\"source_id\"] = sample_2[\"id\"]\n",
    "sample_2[\"source\"] = (\n",
    "    \"attachments/\"\n",
    "    + sample_2[\"id\"].astype(str)\n",
    "    + \".pdf#page=\"\n",
    "    + sample_2[\"page\"].astype(str)\n",
    ")\n",
    "sample_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining extractors for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitz_extractor(pdf, page):\n",
    "    doc = fitz.open(pdf)\n",
    "    return doc[page - 1].get_text()\n",
    "\n",
    "\n",
    "def pypdf2_extractor(pdf, page):\n",
    "    reader = PyPDF2.PdfReader(pdf)\n",
    "    return reader.pages[page - 1].extract_text()\n",
    "\n",
    "\n",
    "def pdfminer_extractor(pdf, page):\n",
    "    texts = [\n",
    "        elem.get_text()\n",
    "        for elem in list(pdfminer_extract_pages(pdf))[page - 1]\n",
    "        if isinstance(elem, pdfminer_LTTextContainer)\n",
    "    ]\n",
    "    return \"\".join(texts)\n",
    "\n",
    "\n",
    "def tika_extractor(pdf, page):\n",
    "    \"\"\"Adapted from: https://github.com/chrismattmann/tika-python/issues/191#issuecomment-612544137\"\"\"\n",
    "    pages_txt = []\n",
    "    data = tika_parser.from_file(pdf, xmlContent=True)\n",
    "    xhtml_data = BeautifulSoup(data[\"content\"])\n",
    "    for i, content in enumerate(xhtml_data.find_all(\"div\", attrs={\"class\": \"page\"})):\n",
    "        _buffer = StringIO()\n",
    "        _buffer.write(str(content))\n",
    "        parsed_content = tika_parser.from_buffer(_buffer.getvalue())\n",
    "        text = parsed_content[\"content\"].strip()\n",
    "        pages_txt.append(text)\n",
    "    return pages_txt[page - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors = [\n",
    "    (\"fitz\", fitz_extractor),\n",
    "    (\"PyPDF2\", pypdf2_extractor),\n",
    "    (\"pdfminer\", pdfminer_extractor),\n",
    "    (\"tika\", tika_extractor),\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for method_name, method_extractor in extractors:\n",
    "    new_df = sample_2.copy()\n",
    "    new_df[\"id\"] = (\n",
    "        method_name + \"_\" + new_df[\"id\"].astype(str) + \"_\" + new_df[\"page\"].astype(str)\n",
    "    )\n",
    "    new_df[\"task\"] = \"Is the line order correct?\"\n",
    "    new_df[\"content\"] = [\n",
    "        \"<pre>\" + method_extractor(row[\"filename\"], row[\"page\"]) + \"</pre>\"\n",
    "        for _, row in new_df.iterrows()\n",
    "    ]\n",
    "    new_df[\"result\"] = None\n",
    "    dfs.append(new_df)\n",
    "sample_2_out = pd.concat(dfs)\n",
    "sample_2_out = sample_2_out.sample(len(sample_2_out))\n",
    "sample_2_out.to_csv(\n",
    "    \"../02_eval_tool/evaluations/pdf_extractors_line_order.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exclude page 1 of X, recurring header/footer contents, and similar things\n",
    "- Missing body text lines are counted as negative findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>absolute</th>\n",
       "      <th>relative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>result</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PyPDF2</th>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>32</td>\n",
       "      <td>0.744186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>7</td>\n",
       "      <td>0.162791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>4</td>\n",
       "      <td>0.093023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fitz</th>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>39</td>\n",
       "      <td>0.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>4</td>\n",
       "      <td>0.093023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">pdfminer</th>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>33</td>\n",
       "      <td>0.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>8</td>\n",
       "      <td>0.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>2</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">tika</th>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>36</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>5</td>\n",
       "      <td>0.116279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>2</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   absolute  relative\n",
       "id       result                      \n",
       "PyPDF2   POSITIVE        32  0.744186\n",
       "         NEUTRAL          7  0.162791\n",
       "         NEGATIVE         4  0.093023\n",
       "fitz     POSITIVE        39  0.906977\n",
       "         NEUTRAL          4  0.093023\n",
       "pdfminer POSITIVE        33  0.767442\n",
       "         NEGATIVE         8  0.186047\n",
       "         NEUTRAL          2  0.046512\n",
       "tika     POSITIVE        36  0.837209\n",
       "         NEUTRAL          5  0.116279\n",
       "         NEGATIVE         2  0.046512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2 = pd.read_csv(\"results/results_2_line_order.csv\")\n",
    "grouped = results_2.groupby(results_2[\"id\"].str.split(\"_\").map(lambda x: x[0]))\n",
    "pd.concat(\n",
    "    (\n",
    "        grouped[\"result\"].value_counts().to_frame(\"absolute\"),\n",
    "        grouped[\"result\"].value_counts(normalize=True).to_frame(\"relative\"),\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word spelling (& spurious newlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>n_pages</th>\n",
       "      <th>page</th>\n",
       "      <th>line</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2665648</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2665648</td>\n",
       "      <td>attachments/2665648.pdf#page=7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2663366</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2663366</td>\n",
       "      <td>attachments/2663366.pdf#page=11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2665480</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2665480</td>\n",
       "      <td>attachments/2665480.pdf#page=64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                      user_type  \\\n",
       "3    2665648  academic_research_institution   \n",
       "196  2663366  academic_research_institution   \n",
       "106  2665480  academic_research_institution   \n",
       "\n",
       "                                              filename  n_pages  page  line  \\\n",
       "3    ../24212003_requirements_for_artificial_intell...        8     7     9   \n",
       "196  ../24212003_requirements_for_artificial_intell...       13    11     2   \n",
       "106  ../24212003_requirements_for_artificial_intell...       64    64     8   \n",
       "\n",
       "     source_id                           source  \n",
       "3      2665648   attachments/2665648.pdf#page=7  \n",
       "196    2663366  attachments/2663366.pdf#page=11  \n",
       "106    2665480  attachments/2665480.pdf#page=64  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_3 = stratified_sample(attachments, \"user_type\", 7)\n",
    "rng_3 = rng(3)\n",
    "sample_3[\"page\"] = sample_3[\"n_pages\"].map(lambda n: rng_3.choice(n) + 1)\n",
    "sample_3[\"line\"] = sample_3[\"id\"].map(lambda _: rng_3.choice(10) + 1)\n",
    "sample_3[\"source_id\"] = sample_3[\"id\"]\n",
    "sample_3[\"source\"] = (\n",
    "    \"attachments/\"\n",
    "    + sample_3[\"id\"].astype(str)\n",
    "    + \".pdf#page=\"\n",
    "    + sample_3[\"page\"].astype(str)\n",
    ")\n",
    "sample_3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining extractors for the remaining libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitz_extractor(pdf, page, line):\n",
    "    doc = fitz.open(pdf)\n",
    "    text = doc[int(page) - 1].get_text()\n",
    "    lines = [l for l in text.splitlines() if len(l) > 5]\n",
    "    return lines[min(len(lines), line) - 1]\n",
    "\n",
    "\n",
    "def tika_extractor(pdf, page, line):\n",
    "    \"\"\"Adapted from: https://github.com/chrismattmann/tika-python/issues/191#issuecomment-612544137\"\"\"\n",
    "    pages_txt = []\n",
    "    data = tika_parser.from_file(pdf, xmlContent=True)\n",
    "    xhtml_data = BeautifulSoup(data[\"content\"])\n",
    "    for i, content in enumerate(xhtml_data.find_all(\"div\", attrs={\"class\": \"page\"})):\n",
    "        _buffer = StringIO()\n",
    "        _buffer.write(str(content))\n",
    "        parsed_content = tika_parser.from_buffer(_buffer.getvalue())\n",
    "        text = parsed_content[\"content\"].strip()\n",
    "        pages_txt.append(text)\n",
    "    text = pages_txt[page - 1]\n",
    "    lines = [l for l in text.splitlines() if len(l) > 5]\n",
    "    return lines[min(len(lines), line) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors = [\n",
    "    (\"fitz\", fitz_extractor),\n",
    "    (\"tika\", tika_extractor),\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for method_name, method_extractor in extractors:\n",
    "    new_df = sample_3.copy()\n",
    "\n",
    "    # Add id, task, and result columns\n",
    "    new_df[\"id\"] = (\n",
    "        method_name + \"_\" + new_df[\"id\"].astype(str) + \"_\" + new_df[\"page\"].astype(str)\n",
    "    )\n",
    "    new_df[\"task\"] = \"Is the highlighted line correct?\"\n",
    "    new_df[\"result\"] = None\n",
    "\n",
    "    # Add content column\n",
    "    contents = []\n",
    "    for _, row in new_df.iterrows():\n",
    "        # Tell the user the line number\n",
    "        content = f\"<span>Line {row['line']}:</span>\"\n",
    "\n",
    "        # If row is not the first line on the page, add previous line as context\n",
    "        if row[\"line\"] > 1:\n",
    "            prev_line = method_extractor(row[\"filename\"], row[\"page\"], row[\"line\"] - 1)\n",
    "            content += \"<pre>\" + prev_line + \"</pre>\"\n",
    "\n",
    "        # Add the line in bold font\n",
    "        line = method_extractor(row[\"filename\"], row[\"page\"], row[\"line\"])\n",
    "        content += '<pre style=\"font-weight: 700;\">' + line + \"</pre>\"\n",
    "\n",
    "        # Add following line as context\n",
    "        next_line = method_extractor(row[\"filename\"], row[\"page\"], row[\"line\"] + 1)\n",
    "        if next_line != line:\n",
    "            content += \"<pre>\" + next_line + \"</pre>\"\n",
    "\n",
    "        contents.append(content)\n",
    "    new_df[\"content\"] = contents\n",
    "\n",
    "    dfs.append(new_df)\n",
    "sample_3_out = pd.concat(dfs)\n",
    "sample_3_out = sample_3_out.sample(len(sample_3_out))\n",
    "sample_3_out.to_csv(\"../02_eval_tool/evaluations/pdf_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>absolute</th>\n",
       "      <th>relative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>result</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fitz</th>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>58</td>\n",
       "      <td>0.983051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">tika</th>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>58</td>\n",
       "      <td>0.983051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEGATIVE</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               absolute  relative\n",
       "id   result                      \n",
       "fitz POSITIVE        58  0.983051\n",
       "     NEGATIVE         1  0.016949\n",
       "tika POSITIVE        58  0.983051\n",
       "     NEGATIVE         1  0.016949"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3 = pd.read_csv(\"results/results_3_words.csv\")\n",
    "grouped = results_3.groupby(results_3[\"id\"].str.split(\"_\").map(lambda x: x[0]))\n",
    "pd.concat(\n",
    "    (\n",
    "        grouped[\"result\"].value_counts().to_frame(\"absolute\"),\n",
    "        grouped[\"result\"].value_counts(normalize=True).to_frame(\"relative\"),\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases, the error was not being able to read the ligature 'ff' in \"sign-off\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Footnote references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>n_pages</th>\n",
       "      <th>page</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2665648</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2665648</td>\n",
       "      <td>attachments/2665648.pdf#page=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2665648</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2665648</td>\n",
       "      <td>attachments/2665648.pdf#page=6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2663366</td>\n",
       "      <td>academic_research_institution</td>\n",
       "      <td>../24212003_requirements_for_artificial_intell...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2663366</td>\n",
       "      <td>attachments/2663366.pdf#page=11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                      user_type  \\\n",
       "3    2665648  academic_research_institution   \n",
       "3    2665648  academic_research_institution   \n",
       "196  2663366  academic_research_institution   \n",
       "\n",
       "                                              filename  n_pages page  \\\n",
       "3    ../24212003_requirements_for_artificial_intell...        8    1   \n",
       "3    ../24212003_requirements_for_artificial_intell...        8    6   \n",
       "196  ../24212003_requirements_for_artificial_intell...       13   11   \n",
       "\n",
       "     source_id                           source  \n",
       "3      2665648   attachments/2665648.pdf#page=1  \n",
       "3      2665648   attachments/2665648.pdf#page=6  \n",
       "196    2663366  attachments/2663366.pdf#page=11  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_4 = stratified_sample(attachments.query(\"id != 2665436\"), \"user_type\", 20)\n",
    "rng_4 = rng(4)\n",
    "sample_4[\"page\"] = sample_4[\"n_pages\"].map(\n",
    "    lambda n: rng_3.choice(n, min(n, 2), replace=False) + 1\n",
    ")\n",
    "sample_4 = sample_4.explode(\"page\")\n",
    "sample_4[\"source_id\"] = sample_4[\"id\"]\n",
    "sample_4[\"source\"] = (\n",
    "    \"attachments/\"\n",
    "    + sample_4[\"id\"].astype(str)\n",
    "    + \".pdf#page=\"\n",
    "    + sample_4[\"page\"].astype(str)\n",
    ")\n",
    "sample_4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define a footnote reference extractor using PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUP = 1\n",
    "import re\n",
    "\n",
    "\n",
    "def wrap(s, high):\n",
    "    if (\n",
    "        high\n",
    "        # Positive match to Arabic numbers or Roman numerals\n",
    "        and re.match(r\"\\s*[\\divx][\\s\\divx,]*$\", s) is not None\n",
    "        # Negative match to common false positives\n",
    "        and re.match(r\"\\s+$|\\s*rd\\s*|\\s*st\\s*|\\s*th\\s*|\\s*\\.\\s*\", s) is None\n",
    "    ):\n",
    "        return f'<code style=\"font-weight: 1000; background-color: #FF0000;\">{s}</code>'\n",
    "    return f\"<code>{s}</code>\"\n",
    "\n",
    "\n",
    "def fitz_extractor(pdf, page):\n",
    "    doc = fitz.open(pdf)\n",
    "    text = doc[int(page) - 1].get_text(\"dict\", flags=16 + 2)\n",
    "    lines = [l for b in text[\"blocks\"] for l in b[\"lines\"]]\n",
    "    lines = [\n",
    "        \"\".join([wrap(s[\"text\"], s[\"flags\"] & SUP) for s in l[\"spans\"]]) for l in lines\n",
    "    ]\n",
    "    return \"<br>\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_4_out = sample_4.copy()\n",
    "\n",
    "sample_4_out[\"id\"] = (\n",
    "    \"fitz_\" + sample_4_out[\"id\"].astype(str) + \"_\" + sample_4_out[\"page\"].astype(str)\n",
    ")\n",
    "sample_4_out[\n",
    "    \"task\"\n",
    "] = \"Footnotes in doc + all footnotes highlighted: 👍; something other than footnote or not all footnotes highlighted: 👎; no footnote in doc: 👌\"\n",
    "sample_4_out[\"content\"] = sample_4_out.apply(\n",
    "    lambda row: fitz_extractor(row[\"filename\"], row[\"page\"]), axis=1\n",
    ")\n",
    "sample_4_out[\"result\"] = None\n",
    "\n",
    "sample_4_out = sample_4_out.sample(len(sample_4_out))\n",
    "sample_4_out.to_csv(\"../02_eval_tool/evaluations/pdf_footnotes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute</th>\n",
       "      <th>relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NO_FOOTNOTES_ON_PAGE</th>\n",
       "      <td>181</td>\n",
       "      <td>0.721116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POSITIVE</th>\n",
       "      <td>61</td>\n",
       "      <td>0.243028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FALSE_NEGATIVE</th>\n",
       "      <td>9</td>\n",
       "      <td>0.035857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      absolute  relative\n",
       "NO_FOOTNOTES_ON_PAGE       181  0.721116\n",
       "POSITIVE                    61  0.243028\n",
       "FALSE_NEGATIVE               9  0.035857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_4 = pd.read_csv(\"results/results_4_footnotes.csv\")\n",
    "pd.concat(\n",
    "    (\n",
    "        results_4[\"result\"].value_counts().to_frame(\"absolute\"),\n",
    "        results_4[\"result\"].value_counts(normalize=True).to_frame(\"relative\"),\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.87\n",
      "Pages containing footnotes: 0.28\n"
     ]
    }
   ],
   "source": [
    "counts = results_4[\"result\"].value_counts()\n",
    "tp, fn = counts[\"POSITIVE\"], counts[\"FALSE_NEGATIVE\"]\n",
    "fp = len(results_4) - tp - fn - counts[\"NO_FOOTNOTES_ON_PAGE\"]\n",
    "print(\"Precision:\", tp / (tp + fp))\n",
    "print(\"Recall:\", round(tp / (tp + fn), 2))\n",
    "print(\"Pages containing footnotes:\", round((tp + fn) / len(results_4), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Footnote resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Experimentally) resolving footnotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from footnote_resolution_v1 import extract_pdf, line_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/Uni/thesis/01_pdf_extractors/footnote_resolution_v1.py:146: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  lines = pd.Series(lines).value_counts()\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for _, row in attachments.iterrows():\n",
    "    pages = extract_pdf(row[\"filename\"])\n",
    "    for page, (lines, footnotes, replacements) in enumerate(pages):\n",
    "        if len(footnotes) == 0:\n",
    "            continue\n",
    "\n",
    "        results[(row[\"id\"], page + 1)] = (lines, footnotes, replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = list(set(map(lambda x: x[0], results.keys())))\n",
    "\n",
    "my_rng = rng(5)\n",
    "pdfs = my_rng.choice(pdfs, 128, shuffle=True, replace=False)\n",
    "\n",
    "sample_5 = []\n",
    "for pdf in pdfs:\n",
    "    pages = list(map(lambda x: x[1], filter(lambda x: x[0] == pdf, results.keys())))\n",
    "    page = my_rng.choice(pages)\n",
    "    sample_5.append(dict(pdf=pdf, page=page, results=results[(pdf, page)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_5_out = []\n",
    "\n",
    "for sample in sample_5:\n",
    "    content = \"\"\n",
    "    lines, footnotes, replacements = sample[\"results\"]\n",
    "    one_resolved = False\n",
    "    for footnote in footnotes:\n",
    "        content += (\n",
    "            f\"<code style=\\\"font-weight: 1000;\\\">Foonote: {footnote['text']}</code><br>\"\n",
    "        )\n",
    "        repl = list(filter(lambda x: x[\"footnote\"] == footnote, replacements))\n",
    "        if len(repl) > 0:\n",
    "            line = repl[0][\"replacement\"][0]\n",
    "            first_repl = line_to_text(lines[line], clean=True)[\n",
    "                len(line_to_text([footnote], clean=True)) :\n",
    "            ]\n",
    "            content += f\"<code>{first_repl.replace('<', '〈')}</code><br>\"\n",
    "\n",
    "            for line in repl[0][\"replacement\"][1:]:\n",
    "                content += f\"    <code>{line_to_text(lines[line], clean=True).replace('<', '〈')}</code><br>\"\n",
    "\n",
    "            one_resolved = True\n",
    "        else:\n",
    "            content += '    <code style=\"font-weight: 1000; background-color: #FF0000;\">No resolution</code>'\n",
    "        content += \"<br><br>\"\n",
    "    sample_5_out.append(\n",
    "        dict(\n",
    "            id=sample[\"pdf\"],\n",
    "            page=sample[\"page\"],\n",
    "            content=content,\n",
    "            result=None\n",
    "            if \"#FF0000\" not in content\n",
    "            else \"SOME_UNRESOLVED\"\n",
    "            if one_resolved\n",
    "            else \"NONE_RESOLVED\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "sample_5_out = pd.DataFrame(sample_5_out)\n",
    "sample_5_out[\"source\"] = (\n",
    "    \"attachments/\"\n",
    "    + sample_5_out[\"id\"].astype(str)\n",
    "    + \".pdf#page=\"\n",
    "    + sample_5_out[\"page\"].astype(str)\n",
    ")\n",
    "sample_5_out[\"task\"] = (\n",
    "    \"Are footnotes correctly resolved? (\"\n",
    "    + \"Anything wrong, including another footnote's text inside a footnotes resolution? 👎 \"\n",
    "    + \"Some footnotes are missing but the one's that are there are good? 👌 \"\n",
    "    + \"All footnotes resolved correctly? 👍) \"\n",
    ")\n",
    "\n",
    "sample_5_out.to_csv(\"../02_eval_tool/evaluations/pdf_footnote_parsing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSITIVE               0.750\n",
       "NONE_RESOLVED          0.141\n",
       "WRONG_RESOLUTION       0.055\n",
       "SOME_UNRESOLVED        0.039\n",
       "FOOTNOTE_UNDETECTED    0.016\n",
       "Name: result, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"results/results_5_footnote_parsing.csv\")[\"result\"].value_counts(\n",
    "    normalize=True\n",
    ").round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
